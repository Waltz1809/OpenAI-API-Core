#!/usr/bin/env python3
"""
Analyze Workflow - PhÃ¢n tÃ­ch ngá»¯ cáº£nh cá»§a content
"""

import os
import threading
import queue
import time
from typing import Dict, List

from core.ai_factory import AIClientFactory
from core.yaml_processor import YamlProcessor
from core.logger import Logger
from core.path_helper import get_path_helper


class AnalyzeWorkflow:
    """Workflow Ä‘á»ƒ phÃ¢n tÃ­ch ngá»¯ cáº£nh."""
    
    def __init__(self, config: Dict, secret: Dict):
        self.config = config
        self.secret = secret
        self.processor = YamlProcessor()
        
        # Setup API client cho context analysis
        self.client = AIClientFactory.create_client(config['context_api'], secret)
        
        # Load prompt
        self.prompt = self._load_prompt(config['paths']['context_prompt_file'])
        
        # Setup paths
        self.input_file = config['active_task']['source_yaml_file']
        self.base_name = self.processor.get_base_name(self.input_file)
        
        # Get SDK code from factory
        self.sdk_code = AIClientFactory.get_sdk_code(config['context_api'])
        
        # Output files (context_dir chá»©a cáº£ output vÃ  log)
        context_subdir = config['paths']['context_dir']

        self.output_file = self.processor.create_output_filename(
            self.input_file,
            context_subdir,
            self.sdk_code,
            "context"
        )
        
        # Temp file for incremental writes
        self.temp_file = self.processor.create_temp_filename(
            f"{self.base_name}_context",
            config['paths']['temp_output'],
            self.sdk_code
        )

        # Logger (cÅ©ng save trong context_subdir)
        self.logger = Logger(
            context_subdir,
            self.base_name,
            self.sdk_code,
            "context"
        )
        
        print(f"ğŸ”§ Context SDK: {self.sdk_code.upper()}")
        print(f"ğŸ¤– Context Model: {self.client.get_model_name()}")
        print(f"ğŸ“ Output: {self.output_file}")
        print(f"ğŸ’¾ Temp: {self.temp_file}")
        print(f"ğŸ“‹ Log: {self.logger.get_log_path()}")
    
    def _load_prompt(self, prompt_file: str) -> str:
        """Load prompt tá»« file."""
        ph = get_path_helper()
        resolved_path = ph.resolve(prompt_file)
        
        if not ph.exists(resolved_path):
            raise FileNotFoundError(f"Context prompt file khÃ´ng tá»“n táº¡i: {prompt_file}")

        with open(resolved_path, 'r', encoding='utf-8') as f:
            return f.read().strip()
    
    def run(self):
        """Cháº¡y context analysis workflow."""
        try:
            # 1. Load vÃ  filter YAML
            print("\nğŸ“– Äang load file YAML...")
            segments = self.processor.load_yaml(self.input_file)
            
            # Filter theo filtering config má»›i
            original_count = len(segments)
            segments = self.processor.filter_segments(
                segments, self.config['filtering']
            )
            
            if len(segments) != original_count:
                print(f"ğŸ“Š ÄÃ£ filter: {original_count} -> {len(segments)} segments")
            
            print(f"ğŸ“Š Tá»•ng cá»™ng {len(segments)} segments cáº§n phÃ¢n tÃ­ch")
            
            # 2. XÃ³a temp file cÅ© náº¿u cÃ³
            if os.path.exists(self.temp_file):
                os.remove(self.temp_file)
                print(f"ğŸ—‘ï¸ ÄÃ£ xÃ³a temp file cÅ©")
            
            # 3. PhÃ¢n tÃ­ch ngá»¯ cáº£nh (ghi incremental vÃ o temp file)
            print("\nğŸ” Äang phÃ¢n tÃ­ch ngá»¯ cáº£nh...")
            self._analyze_segments(segments)
            print(f"âœ… ÄÃ£ phÃ¢n tÃ­ch xong, Ä‘ang load tá»« temp file...")
            
            # 4. Load temp file vÃ  sort theo thá»© tá»± gá»‘c
            analyzed_segments = self.processor.load_yaml(self.temp_file)
            print(f"ğŸ“Š Äang sáº¯p xáº¿p láº¡i theo thá»© tá»± gá»‘c...")
            analyzed_segments = self.processor.sort_by_original_order(
                analyzed_segments, segments
            )
            
            # 5. Clean vÃ  save final file
            print(f"\nğŸ§¹ Äang clean vÃ  save final file...")
            if self.config['cleaner']['enabled']:
                for segment in analyzed_segments:
                    if 'content' in segment and segment['content']:
                        segment['content'] = self.processor.clean_content(segment['content'])
            
            # 5.1. Extract titles tá»« content (náº¿u context cÃ³ dá»‹ch title)
            print(f"ğŸ·ï¸ Äang extract titles tá»« content...")
            extracted_count = self._extract_titles_from_content(analyzed_segments)
            if extracted_count > 0:
                print(f"âœ… ÄÃ£ extract {extracted_count} titles tá»« content")
            
            self.processor.save_yaml(analyzed_segments, self.output_file)
            print(f"âœ… ÄÃ£ save final file: {self.output_file}")
            
            # 6. XÃ³a temp file
            if os.path.exists(self.temp_file):
                os.remove(self.temp_file)
                print(f"ğŸ—‘ï¸ ÄÃ£ xÃ³a temp file")
            
            # 6. Log summary - Ä‘áº¿m tá»« logger stats
            successful = self.logger.request_count  # Sá»‘ request thÃ nh cÃ´ng (cÃ³ token_info)
            failed = len(segments) - successful
            self.logger.log_summary(
                len(segments), successful, failed, self.client.get_model_name()
            )
            
            # 7. Log failed segments (Ä‘á»ƒ cÃ³ thá»ƒ retry sau)
            if failed > 0:
                print(f"âš ï¸ CÃ³ {failed} segments tháº¥t báº¡i")
                analyzed_ids = {seg['id'] for seg in analyzed_segments if 'id' in seg}
                original_ids = {seg['id'] for seg in segments if 'id' in seg}
                failed_ids = original_ids - analyzed_ids
                
                if failed_ids:
                    self.logger.log_message(
                        f"Failed segments: {', '.join(sorted(failed_ids))}",
                        "ERROR"
                    )
            
            print(f"\nğŸ‰ PHÃ‚N TÃCH HOÃ€N THÃ€NH!")
            print(f"âœ… ThÃ nh cÃ´ng: {successful}/{len(segments)} segments")
            if failed > 0:
                print(f"âš ï¸ Tháº¥t báº¡i: {failed} segments (xem log Ä‘á»ƒ retry)")
            print(f"ğŸ“ Output: {self.output_file}")
            print(f"ğŸ“‹ Log: {self.logger.get_log_path()}")
            
        except Exception as e:
            print(f"âŒ Lá»—i trong analyze workflow: {e}")
            raise
    
    def _analyze_segments(self, segments: List[Dict]):
        """PhÃ¢n tÃ­ch ngá»¯ cáº£nh cá»§a segments báº±ng threading vÃ  ghi incremental vÃ o temp file."""
        q = queue.Queue()
        lock = threading.Lock()
        processed_count = {'value': 0}
        
        # ÄÆ°a segments vÃ o queue
        for segment in segments:
            q.put(segment)
        
        # Threading config
        concurrent_requests = self.config['context_api']['concurrent_requests']
        num_threads = min(concurrent_requests, len(segments))
        threads = []
        
        print(f"ğŸ”§ Sá»­ dá»¥ng {num_threads} threads Ä‘á»“ng thá»i...")
        
        # Táº¡o vÃ  cháº¡y threads
        for _ in range(num_threads):
            t = threading.Thread(
                target=self._analysis_worker,
                args=(q, lock, len(segments), processed_count)
            )
            t.daemon = True
            t.start()
            threads.append(t)
        
        # Äá»£i hoÃ n thÃ nh
        for t in threads:
            t.join()
    
    def _analysis_worker(self, q: queue.Queue, lock: threading.Lock, 
                        total_segments: int, processed_count: Dict):
        """Worker thread Ä‘á»ƒ phÃ¢n tÃ­ch context vÃ  ghi vÃ o temp file."""
        while not q.empty():
            try:
                segment = q.get(block=False)
                segment_id = segment['id']
                
                with lock:
                    processed_count['value'] += 1
                    current = processed_count['value']
                    print(f"[{current}/{total_segments}] ğŸ” {segment_id}")
                
                try:
                    # PhÃ¢n tÃ­ch context
                    user_prompt = f"PhÃ¢n tÃ­ch ngá»¯ cáº£nh cá»§a Ä‘oáº¡n vÄƒn sau:\n\n{segment['content']}"
                    
                    analysis, token_info = self.client.generate_content(
                        self.prompt,
                        user_prompt
                    )
                    
                    # Táº¡o segment má»›i vá»›i analysis
                    analyzed_segment = {
                        'id': segment['id'],
                        'title': segment['title'],
                        'content': analysis  # Replace content vá»›i analysis
                    }
                    
                    # Ghi vÃ o temp file ngay (thread-safe)
                    with lock:
                        self.processor.append_segment_to_temp(analyzed_segment, self.temp_file)
                        self.logger.log_segment(
                            segment_id, "THÃ€NH CÃ”NG", token_info=token_info
                        )
                
                except Exception as e:
                    with lock:
                        # Giá»¯ segment gá»‘c náº¿u lá»—i
                        self.processor.append_segment_to_temp(segment, self.temp_file)
                        self.logger.log_segment(
                            segment_id, "THáº¤T Báº I", str(e)
                        )
                
                q.task_done()
                
                # Delay Ä‘á»ƒ trÃ¡nh rate limit
                time.sleep(self.config['context_api'].get('delay', 1))
                
            except queue.Empty:
                break
    
    def _extract_titles_from_content(self, segments: List[Dict]) -> int:
        """
        Extract title tá»« dÃ²ng Ä‘áº§u cá»§a content vÃ  update field title.
        DÃ¹ng cho context analysis náº¿u cÃ³ dá»‹ch title trong content.
        
        Returns:
            int: Sá»‘ segments Ä‘Ã£ extract title
        """
        extracted = 0
        
        for segment in segments:
            if 'content' not in segment or not segment['content']:
                continue
            
            content = segment['content']
            lines = content.split('\n')
            
            # Bá» qua cÃ¡c dÃ²ng rá»—ng á»Ÿ Ä‘áº§u
            first_line_idx = 0
            for i, line in enumerate(lines):
                if line.strip():
                    first_line_idx = i
                    break
            
            if first_line_idx >= len(lines):
                continue
            
            first_line = lines[first_line_idx].strip()
            
            # Loáº¡i bá» dáº¥u ' á»Ÿ Ä‘áº§u náº¿u cÃ³ (tá»« splitter)
            if first_line.startswith("'"):
                first_line = first_line[1:].strip()
            
            # Update title náº¿u cÃ³ ná»™i dung
            if first_line:
                segment['title'] = first_line
                extracted += 1
        
        return extracted

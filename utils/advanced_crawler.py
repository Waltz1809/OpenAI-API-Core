import os
import sys
import re
import json
import time
from urllib.parse import urljoin, urlparse
from bs4 import BeautifulSoup
from playwright.sync_api import sync_playwright

class AdvancedNovelCrawler:
    def __init__(self, headless=True, delay=2, timeout=30000, browser_type='chromium'):
        """
        Khá»Ÿi táº¡o crawler nÃ¢ng cao vá»›i Playwright
        
        Args:
            headless: Cháº¡y browser áº©n (True) hay hiá»ƒn thá»‹ (False)
            delay: Thá»i gian delay giá»¯a cÃ¡c request (giÃ¢y)
            timeout: Timeout cho page load (ms)
            browser_type: 'chromium', 'firefox', hoáº·c 'edge'
        """
        self.headless = headless
        self.delay = delay
        self.timeout = timeout
        self.browser_type = browser_type
        self.browser = None
        self.context = None
        self.page = None
        
    def start_browser(self):
        """Khá»Ÿi Ä‘á»™ng browser"""
        self.playwright = sync_playwright().start()
        
        # Chá»n browser engine
        if self.browser_type == 'edge':
            try:
                browser_engine = self.playwright.chromium
                channel = 'msedge'
            except:
                print("âš ï¸  Edge khÃ´ng kháº£ dá»¥ng, chuyá»ƒn sang Chromium")
                browser_engine = self.playwright.chromium
                channel = None
        elif self.browser_type == 'firefox':
            browser_engine = self.playwright.firefox
            channel = None
        else:
            browser_engine = self.playwright.chromium
            channel = None
        
        # Args chung Ä‘á»ƒ bypass detection
        common_args = [
            '--no-sandbox',
            '--disable-blink-features=AutomationControlled',
            '--disable-web-security',
            '--disable-features=VizDisplayCompositor',
            '--disable-background-timer-throttling',
            '--disable-backgrounding-occluded-windows',
            '--disable-renderer-backgrounding',
            '--disable-field-trial-config',
            '--disable-ipc-flooding-protection',
            '--no-first-run',
            '--no-default-browser-check',
            '--disable-extensions-except',
            '--disable-plugins-discovery',
            '--disable-component-extensions-with-background-pages'
        ]
        
        # Khá»Ÿi táº¡o browser
        if channel:
            self.browser = browser_engine.launch(
                headless=self.headless,
                channel=channel,
                args=common_args
            )
        else:
            self.browser = browser_engine.launch(
                headless=self.headless,
                args=common_args
            )
        
        # Táº¡o context vá»›i fake fingerprint
        self.context = self.browser.new_context(
            user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36 Edg/120.0.0.0',
            viewport={'width': 1920, 'height': 1080},
            screen={'width': 1920, 'height': 1080},
            device_scale_factor=1,
            is_mobile=False,
            has_touch=False,
            color_scheme='light',
            extra_http_headers={
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
                'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8,en-GB;q=0.7,en-US;q=0.6',
                'Accept-Encoding': 'gzip, deflate, br',
                'Cache-Control': 'max-age=0',
                'Sec-Ch-Ua': '"Not_A Brand";v="8", "Chromium";v="120", "Microsoft Edge";v="120"',
                'Sec-Ch-Ua-Mobile': '?0',
                'Sec-Ch-Ua-Platform': '"Windows"',
                'Sec-Fetch-Dest': 'document',
                'Sec-Fetch-Mode': 'navigate',
                'Sec-Fetch-Site': 'none',
                'Sec-Fetch-User': '?1',
                'Upgrade-Insecure-Requests': '1',
            }
        )
        
        self.page = self.context.new_page()
        self.page.set_default_timeout(self.timeout)
        
        # Adblock bypass scripts
        self.page.add_init_script("""
            // Hide webdriver property
            Object.defineProperty(navigator, 'webdriver', {
                get: () => undefined,
            });
            
            // Mock plugins
            Object.defineProperty(navigator, 'plugins', {
                get: () => [
                    {
                        name: 'Chrome PDF Plugin',
                        description: 'Portable Document Format',
                        length: 1,
                    },
                    {
                        name: 'Chrome PDF Viewer',
                        description: '',
                        length: 1,
                    },
                    {
                        name: 'Native Client',
                        description: '',
                        length: 1,
                    }
                ],
            });
            
            // Mock language
            Object.defineProperty(navigator, 'languages', {
                get: () => ['zh-CN', 'zh', 'en-US', 'en'],
            });
            
            // Mock chrome object
            window.chrome = {
                runtime: {},
                loadTimes: function() {},
                csi: function() {},
                app: {}
            };
            
            // Disable adblock detection
            Object.defineProperty(window, 'navigator', {
                value: new Proxy(navigator, {
                    has: (target, key) => (key === 'webdriver' ? false : key in target),
                    get: (target, key) =>
                        key === 'webdriver' ? undefined :
                        key === 'plugins' ? target.plugins :
                        key === 'languages' ? ['zh-CN', 'zh', 'en-US', 'en'] :
                        typeof target[key] === 'function' ? target[key].bind(target) : target[key]
                }),
                configurable: false
            });
            
            // Block common adblock detection
            const originalQuery = window.document.querySelector;
            const originalQueryAll = window.document.querySelectorAll;
            
            window.document.querySelector = function(selector) {
                if (selector && selector.includes && (
                    selector.includes('adblock') || 
                    selector.includes('ad-block') ||
                    selector.includes('adblocker')
                )) {
                    return null;
                }
                return originalQuery.call(this, selector);
            };
            
            window.document.querySelectorAll = function(selector) {
                if (selector && selector.includes && (
                    selector.includes('adblock') || 
                    selector.includes('ad-block') ||
                    selector.includes('adblocker')
                )) {
                    return [];
                }
                return originalQueryAll.call(this, selector);
            };
            
            // Mock common adblock detection variables
            window.canRunAds = true;
            window.isAdBlockActive = false;
            window.adBlockEnabled = false;
            window.blockAdBlock = undefined;
            window.AdBlockDetector = undefined;
            
            console.log('Anti-adblock bypass loaded');
        """)
        
    def close_browser(self):
        """ÄÃ³ng browser"""
        if self.page:
            self.page.close()
        if self.context:
            self.context.close()
        if self.browser:
            self.browser.close()
        if hasattr(self, 'playwright'):
            self.playwright.stop()
    
    def extract_content_from_page(self, url):
        """
        TrÃ­ch xuáº¥t ná»™i dung tá»« trang web.
        
        Args:
            url: URL cá»§a trang
            
        Returns:
            Tuple (tiÃªu Ä‘á», ná»™i dung, next_url)
        """
        try:
            print(f"Äang táº£i trang: {url}")
            
            # Navigate Ä‘áº¿n trang
            response = self.page.goto(url, wait_until='networkidle')
            
            if not response or response.status >= 400:
                print(f"Lá»—i HTTP {response.status if response else 'Unknown'}")
                return None, None, None
            
            # Äá»£i trang load
            self.page.wait_for_timeout(1000)
            
            # Remove adblock popup
            self.page.evaluate("""
                // Remove common adblock overlays
                const selectors = [
                    '[class*="adblock"]',
                    '[id*="adblock"]',
                    '[class*="ad-block"]', 
                    '[id*="ad-block"]',
                    '.adblock-overlay',
                    '.adblock-popup',
                    '.anti-adblock',
                    '.adblocker-overlay'
                ];
                
                selectors.forEach(selector => {
                    const elements = document.querySelectorAll(selector);
                    elements.forEach(el => {
                        if (el && el.style) {
                            el.style.display = 'none';
                            el.remove();
                        }
                    });
                });
                
                // Also try to click any "Continue" or "Disable adblock" buttons
                const buttons = document.querySelectorAll('button, a, div[role="button"]');
                buttons.forEach(btn => {
                    const text = btn.textContent.toLowerCase();
                    if (text.includes('continue') || text.includes('tiáº¿p tá»¥c') || 
                        text.includes('Ä‘Ã³ng') || text.includes('close')) {
                        btn.click();
                    }
                });
            """)
            
            # Äá»£i content load Ä‘áº§y Ä‘á»§
            print("â³ Äá»£i content load...")
            self.page.wait_for_timeout(3000)
            
            # Kiá»ƒm tra lá»—i
            page_content = self.page.content()
            error_indicators = [
                'å…§å®¹åŠ è¼‰å¤±æ•—',
                'è¯·åˆ·æ–°',
                'æ›´æ›ç€è¦½å™¨',
                'åŠ è½½å¤±è´¥',
                'loading failed'
            ]
            
            for indicator in error_indicators:
                if indicator.lower() in page_content.lower():
                    print(f"âš ï¸  PhÃ¡t hiá»‡n thÃ´ng bÃ¡o lá»—i: {indicator}")
                    print("Thá»­ refresh trang...")
                    self.page.reload(wait_until='networkidle')
                    self.page.wait_for_timeout(3000)
                    break
            
            # Láº¥y title
            title = self.page.evaluate("""
                () => {
                    const titleEl = document.querySelector('#mlfy_main_text h1');
                    return titleEl ? titleEl.innerText.trim() : 'KhÃ´ng cÃ³ tiÃªu Ä‘á»';
                }
            """)
            
            # TrÃ­ch xuáº¥t ná»™i dung trá»±c tiáº¿p
            content = self.page.evaluate("""
                () => {
                    const textContent = document.getElementById('TextContent');
                    if (!textContent) return null;
                    
                    const paragraphs = Array.from(textContent.querySelectorAll('p'));
                    return paragraphs.map(p => p.innerText.trim()).join('\\n\\n');
                }
            """)

            if not content:
                print(f"âŒ KhÃ´ng thá»ƒ trÃ­ch xuáº¥t ná»™i dung tá»« #TextContent")
                return title, None, None
            
            # Clean up content
            content = self.clean_content(content)
            
            # TÃ¬m link trang tiáº¿p theo
            next_url = self.page.evaluate(f"""
                () => {{
                    const navDiv = document.querySelector('.mlfy_page');
                    if (!navDiv) return null;
                    
                    const links = navDiv.querySelectorAll('a[href]');
                    for (let link of links) {{
                        if (link.textContent.includes('ä¸‹ä¸€é¡µ')) {{
                            const href = link.getAttribute('href');
                            if (href.startsWith('http')) {{
                                return href;
                            }} else {{
                                return new URL(href, '{url}').href;
                            }}
                        }}
                    }}
                    return null;
                }}
            """)
            
            print(f"âœ… TrÃ­ch xuáº¥t thÃ nh cÃ´ng: {title}")
            return title, content, next_url
            
        except Exception as e:
            print(f"âŒ Lá»—i khi trÃ­ch xuáº¥t tá»« {url}: {e}")
            return None, None, None
    
    def clean_content(self, content):
        """
        Clean content nháº¹ nhÃ ng, giá»¯ nguyÃªn structure
        """
        if not content:
            return content
            
        # Chá»‰ fix nhá»¯ng encoding issues rÃµ rÃ ng
        replacements = {
            '\u200b': '',  # Zero-width space
            '\u200c': '',  # Zero-width non-joiner
            '\u200d': '',  # Zero-width joiner
            '\ufeff': '',  # Byte order mark
        }
        
        for old, new in replacements.items():
            content = content.replace(old, new)
        
        # Chá»‰ remove excessive line breaks, khÃ´ng thay Ä‘á»•i structure
        content = re.sub(r'\n\s*\n\s*\n+', '\n\n', content)
        
        return content.strip()
    
    def _get_base_chapter_id(self, url):
        """
        TrÃ­ch xuáº¥t ID chÆ°Æ¡ng cÆ¡ báº£n tá»« URL Ä‘á»ƒ gá»™p cÃ¡c pháº§n cá»§a cÃ¹ng má»™t chÆ°Æ¡ng.
        VÃ­ dá»¥: '.../274968.html' -> '274968'
               '.../274968_2.html' -> '274968'
        """
        if not url:
            return None
        try:
            filename = os.path.basename(urlparse(url).path)
            # Bá» pháº§n Ä‘uÃ´i .html, vÃ­ dá»¥ '274968_2'
            chapter_part = filename.split('.html')[0]
            # Láº¥y pháº§n trÆ°á»›c dáº¥u '_', vÃ­ dá»¥ '274968'
            base_chapter_id = chapter_part.split('_')[0]
            return base_chapter_id
        except (IndexError, AttributeError):
            print(f"âš ï¸  KhÃ´ng thá»ƒ parse ID chÆ°Æ¡ng tá»« URL: {url}")
            return None
    
    def crawl_from_url(self, start_url, output_dir=None, max_chapters=None, save_format='txt'):
        """
        Crawl tá»« URL báº¯t Ä‘áº§u, cÃ³ kháº£ nÄƒng gá»™p cÃ¡c pháº§n cá»§a cÃ¹ng má»™t chÆ°Æ¡ng.
        
        Args:
            start_url: URL báº¯t Ä‘áº§u
            output_dir: ThÆ° má»¥c lÆ°u output
            max_chapters: Sá»‘ chÆ°Æ¡ng tá»‘i Ä‘a cáº§n crawl
            save_format: Äá»‹nh dáº¡ng lÆ°u file
            
        Returns:
            List cÃ¡c (title, content, url) Ä‘Ã£ crawl
        """
        results = []
        current_url = start_url
        chapter_count = 0
        
        self.start_browser()
        
        try:
            if output_dir:
                os.makedirs(output_dir, exist_ok=True)
            
            while current_url and (max_chapters is None or chapter_count < max_chapters):
                print(f"\nğŸŒ Báº¯t Ä‘áº§u crawl chÆ°Æ¡ng {chapter_count + 1} tá»«: {current_url}")
                
                # TrÃ­ch xuáº¥t ná»™i dung trang Ä‘áº§u tiÃªn cá»§a chÆ°Æ¡ng
                title, first_content, next_url = self.extract_content_from_page(current_url)
                
                if not title or not first_content:
                    print("âŒ KhÃ´ng thá»ƒ trÃ­ch xuáº¥t ná»™i dung, dá»«ng crawl.")
                    break
                
                full_chapter_content = [first_content]
                page_in_chapter_url = current_url

                # VÃ²ng láº·p Ä‘á»ƒ gá»™p cÃ¡c pháº§n cá»§a cÃ¹ng má»™t chÆ°Æ¡ng
                while True:
                    base_current_id = self._get_base_chapter_id(page_in_chapter_url)
                    base_next_id = self._get_base_chapter_id(next_url)
                    
                    if base_current_id and base_next_id and base_current_id == base_next_id:
                        # Trang tiáº¿p theo lÃ  má»™t pháº§n cá»§a chÆ°Æ¡ng hiá»‡n táº¡i
                        page_in_chapter_url = next_url
                        print(f"  Found chapter part: {page_in_chapter_url}")
                        
                        # Chá»‰ cáº§n láº¥y ná»™i dung vÃ  link trang káº¿ tiáº¿p
                        _, part_content, next_url = self.extract_content_from_page(page_in_chapter_url)
                        
                        if part_content:
                            full_chapter_content.append(part_content)
                        else:
                            print("  KhÃ´ng thá»ƒ láº¥y ná»™i dung pháº§n nÃ y, káº¿t thÃºc chÆ°Æ¡ng táº¡i Ä‘Ã¢y.")
                            break
                    else:
                        # Trang tiáº¿p theo lÃ  chÆ°Æ¡ng má»›i hoáº·c Ä‘Ã£ háº¿t, káº¿t thÃºc chÆ°Æ¡ng hiá»‡n táº¡i
                        break

                # Gá»™p ná»™i dung vÃ  lÆ°u
                final_content = '\n\n'.join(full_chapter_content)
                results.append((title, final_content, current_url))
                
                if output_dir:
                    self.save_content(
                        title, final_content, output_dir, chapter_count + 1, save_format
                    )
                else:
                    print(f"\n=== {title} ===")
                    print(final_content[:300] + "..." if len(final_content) > 300 else final_content)
                    print(f"\n(ÄÃ£ gá»™p {len(full_chapter_content)} pháº§n)")
                    print("\n" + "="*50 + "\n")

                chapter_count += 1
                current_url = next_url # Chuyá»ƒn sang chÆ°Æ¡ng má»›i
                
                if current_url:
                    print(f"â³ Äá»£i {self.delay} giÃ¢y trÆ°á»›c khi crawl chÆ°Æ¡ng tiáº¿p theo...")
                    time.sleep(self.delay)
            
        except KeyboardInterrupt:
            print("\nâš ï¸  NgÆ°á»i dÃ¹ng dá»«ng crawl")
        except Exception as e:
            print(f"âŒ Lá»—i nghiÃªm trá»ng: {e}")
        finally:
            self.close_browser()
        
        print(f"\nğŸ‰ HoÃ n thÃ nh! ÄÃ£ crawl {len(results)} chÆ°Æ¡ng.")
        return results
    
    def save_content(self, title, content, output_dir, page_num, save_format):
        """
        LÆ°u ná»™i dung vÃ o file
        
        Args:
            title: TiÃªu Ä‘á»
            content: Ná»™i dung
            output_dir: ThÆ° má»¥c lÆ°u
            page_num: Sá»‘ thá»© tá»± trang
            save_format: Äá»‹nh dáº¡ng lÆ°u
        """
        # Táº¡o tÃªn file an toÃ n
        safe_title = re.sub(r'[^\w\s-]', '', title).strip()
        safe_title = re.sub(r'[-\s]+', '_', safe_title)
        
        base_filename = f"{page_num:03d}_{safe_title}"
        
        if save_format in ['txt', 'both']:
            txt_file = os.path.join(output_dir, f"{base_filename}.txt")
            with open(txt_file, 'w', encoding='utf-8') as f:
                f.write(f"{title}\n\n{content}")
            print(f"ğŸ“„ ÄÃ£ lÆ°u: {txt_file}")
        
        if save_format in ['json', 'both']:
            json_file = os.path.join(output_dir, f"{base_filename}.json")
            data = {
                'title': title,
                'content': content,
                'page_number': page_num
            }
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            print(f"ğŸ“‹ ÄÃ£ lÆ°u: {json_file}")

def main():
    print("ğŸš€ Advanced Novel Crawler vá»›i Font Analysis")
    print("=" * 60)
    
    # Chá»n browser
    print("Chá»n browser:")
    print("1. Edge (khuyáº¿n nghá»‹)")
    print("2. Chromium")
    print("3. Firefox")
    
    browser_choice = input("Nháº­p lá»±a chá»n (1/2/3) [máº·c Ä‘á»‹nh: 1]: ").strip() or '1'
    
    if browser_choice == '1':
        browser_type = 'edge'
    elif browser_choice == '3':
        browser_type = 'firefox'
    else:
        browser_type = 'chromium'
    
    # Cáº¥u hÃ¬nh crawler
    headless_input = input("Cháº¡y browser áº©n? (y/n) [máº·c Ä‘á»‹nh: n Ä‘á»ƒ debug]: ").strip().lower()
    headless = headless_input == 'y'
    
    delay_input = input("Delay giá»¯a cÃ¡c trang (giÃ¢y) [máº·c Ä‘á»‹nh: 3]: ").strip()
    delay = int(delay_input) if delay_input else 3
    
    crawler = AdvancedNovelCrawler(headless=headless, delay=delay, browser_type=browser_type)
    
    # Crawl tá»« URL
    start_url = input("Nháº­p URL báº¯t Ä‘áº§u: ").strip()
    
    output_dir = input("Nháº­p thÆ° má»¥c lÆ°u file (Ä‘á»ƒ trá»‘ng Ä‘á»ƒ chá»‰ hiá»ƒn thá»‹): ").strip()
    if output_dir == "":
        output_dir = None
    
    max_chapters_input = input("Sá»‘ chÆ°Æ¡ng tá»‘i Ä‘a (Ä‘á»ƒ trá»‘ng = khÃ´ng giá»›i háº¡n): ").strip()
    max_chapters = int(max_chapters_input) if max_chapters_input else None
    
    if output_dir:
        save_format = input("Äá»‹nh dáº¡ng lÆ°u (txt/json/both) [máº·c Ä‘á»‹nh: txt]: ").strip() or 'txt'
    else:
        save_format = 'txt'
    
    print(f"\nğŸ”§ Sá»­ dá»¥ng {browser_type.title()} browser")
    crawler.crawl_from_url(start_url, output_dir, max_chapters, save_format)

if __name__ == "__main__":
    main() 
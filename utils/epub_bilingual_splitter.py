#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
EPUB Bilingual Splitter
TÃ¡ch ná»™i dung song ngá»¯ (Trung-Nháº­t) tá»« EPUB thÃ nh 2 file YAML riÃªng biá»‡t
"""

import os
import re
import yaml
import zipfile
from pathlib import Path
from typing import Dict, List, Tuple
from bs4 import BeautifulSoup


class CustomDumper(yaml.Dumper):
    """Custom YAML Dumper Ä‘á»ƒ format Ä‘áº¹p cho multi-line strings"""
    def represent_scalar(self, tag, value, style=None):
        if tag == 'tag:yaml.org,2002:str' and "\n" in value:
            style = '|'
        return super().represent_scalar(tag, value, style)


def represent_multiline_string(dumper, data):
    """Representer cho multi-line strings"""
    if "\n" in data:
        return dumper.represent_scalar('tag:yaml.org,2002:str', data, style='|')
    return dumper.represent_scalar('tag:yaml.org,2002:str', data)


class EPUBBilingualSplitter:
    """Class Ä‘á»ƒ tÃ¡ch ná»™i dung song ngá»¯ tá»« EPUB"""
    
    def __init__(self, epub_path: str):
        """
        Khá»Ÿi táº¡o splitter
        
        Args:
            epub_path: ÄÆ°á»ng dáº«n Ä‘áº¿n file EPUB
        """
        self.epub_path = epub_path
        self.temp_dir = None
        self.chinese_segments = []
        self.japanese_segments = []
        
    def extract_epub(self) -> str:
        """
        Giáº£i nÃ©n EPUB file
        
        Returns:
            str: ÄÆ°á»ng dáº«n Ä‘áº¿n thÆ° má»¥c Ä‘Ã£ giáº£i nÃ©n
        """
        # Táº¡o thÆ° má»¥c temp Ä‘á»ƒ giáº£i nÃ©n
        epub_name = Path(self.epub_path).stem
        temp_dir = Path(self.epub_path).parent / f"_temp_{epub_name}"
        
        # Giáº£i nÃ©n EPUB (thá»±c cháº¥t lÃ  file ZIP)
        with zipfile.ZipFile(self.epub_path, 'r') as zip_ref:
            zip_ref.extractall(temp_dir)
        
        self.temp_dir = temp_dir
        print(f"âœ“ ÄÃ£ giáº£i nÃ©n EPUB vÃ o: {temp_dir}")
        return str(temp_dir)
    
    def find_xhtml_files(self) -> List[str]:
        """
        TÃ¬m táº¥t cáº£ file XHTML trong EPUB (trá»« TOC vÃ  p-001)
        
        Returns:
            List[str]: Danh sÃ¡ch Ä‘Æ°á»ng dáº«n Ä‘áº¿n cÃ¡c file XHTML
        """
        if not self.temp_dir:
            return []
        
        xhtml_files = []
        
        # TÃ¬m táº¥t cáº£ file .xhtml
        for file in Path(self.temp_dir).rglob("*.xhtml"):
            # Bá» qua cÃ¡c file Ä‘áº·c biá»‡t
            file_name = file.name.lower()
            
            # Bá» qua p-001.xhtml
            if file_name == 'p-001.xhtml':
                continue
                
            if any(skip in file_name for skip in ['toc', 'nav', 'cover', 'copyright']):
                continue
            xhtml_files.append(str(file))
        
        # Sort theo tÃªn file Ä‘á»ƒ Ä‘áº£m báº£o thá»© tá»±
        xhtml_files.sort()
        
        print(f"âœ“ TÃ¬m tháº¥y {len(xhtml_files)} file XHTML (Ä‘Ã£ bá» qua p-001)")
        return xhtml_files
    
    def parse_xhtml_file(self, xhtml_path: str, chapter_number: int, max_chars: int = 2000) -> Tuple[List[Dict], List[Dict]]:
        """
        Parse má»™t file XHTML vÃ  tÃ¡ch ná»™i dung Trung-Nháº­t
        
        Args:
            xhtml_path: ÄÆ°á»ng dáº«n Ä‘áº¿n file XHTML
            chapter_number: Sá»‘ thá»© tá»± chapter
            max_chars: Sá»‘ kÃ½ tá»± tá»‘i Ä‘a cho má»—i segment
            
        Returns:
            Tuple[List[Dict], List[Dict]]: (chinese_segments, japanese_segments)
        """
        with open(xhtml_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        soup = BeautifulSoup(content, 'html.parser')
        
        # TÃ¬m tháº» <div class="main">
        main_div = soup.find('div', class_='main')
        
        if not main_div:
            print(f"   âš ï¸  KhÃ´ng tÃ¬m tháº¥y <div class='main'> trong {Path(xhtml_path).name}")
            return ([], [])
        
        # Láº¥y táº¥t cáº£ tháº» <p> trong main_div
        paragraphs = main_div.find_all('p')
        
        if len(paragraphs) < 2:
            print(f"   âš ï¸  KhÃ´ng Ä‘á»§ paragraphs trong {Path(xhtml_path).name}")
            return ([], [])
        
        # 2 dÃ²ng Ä‘áº§u tiÃªn lÃ  title (1 Trung, 1 Nháº­t)
        chinese_title = None
        japanese_title = None
        
        # XÃ¡c Ä‘á»‹nh title dá»±a vÃ o style
        for i in range(min(2, len(paragraphs))):
            p = paragraphs[i]
            text = p.get_text(strip=True)
            style = p.get('style', '')
            
            if 'opacity' in style.lower() and '0.4' in style:
                japanese_title = text
            else:
                chinese_title = text
        
        # Fallback náº¿u khÃ´ng tÃ¬m Ä‘Æ°á»£c title
        if not chinese_title:
            chinese_title = f"Chapter {chapter_number}"
        if not japanese_title:
            japanese_title = f"Chapter {chapter_number}"
        
        # Láº¥y ná»™i dung tá»« dÃ²ng thá»© 3 trá»Ÿ Ä‘i
        chinese_content = []
        japanese_content = []
        
        for p in paragraphs[2:]:  # Bá» qua 2 dÃ²ng title
            text = p.get_text(strip=True)
            if not text:
                continue
            
            # Kiá»ƒm tra style attribute
            style = p.get('style', '')
            
            # Náº¿u cÃ³ opacity:0.4 thÃ¬ lÃ  tiáº¿ng Nháº­t
            if 'opacity' in style.lower() and '0.4' in style:
                japanese_content.append(text)
            else:
                # CÃ²n láº¡i lÃ  tiáº¿ng Trung
                chinese_content.append(text)
        
        # Chia thÃ nh segments theo max_chars
        chinese_segments = self._split_into_segments(
            chinese_content, chinese_title, chapter_number, max_chars
        )
        japanese_segments = self._split_into_segments(
            japanese_content, japanese_title, chapter_number, max_chars
        )
        
        return (chinese_segments, japanese_segments)
    
    def _split_into_segments(self, content_lines: List[str], title: str, 
                            chapter_number: int, max_chars: int) -> List[Dict]:
        """
        Chia ná»™i dung thÃ nh cÃ¡c segments dá»±a trÃªn sá»‘ kÃ½ tá»±
        
        Args:
            content_lines: List cÃ¡c dÃ²ng ná»™i dung
            title: TiÃªu Ä‘á» chapter
            chapter_number: Sá»‘ chapter
            max_chars: Sá»‘ kÃ½ tá»± tá»‘i Ä‘a má»—i segment
            
        Returns:
            List[Dict]: List cÃ¡c segment
        """
        if not content_lines:
            return []
        
        segments = []
        current_segment = []
        current_length = 0
        segment_counter = 1
        
        for line in content_lines:
            # Äáº¿m kÃ½ tá»± khÃ´ng cÃ³ khoáº£ng tráº¯ng
            line_length = len(re.sub(r'\s+', '', line))
            
            # Náº¿u thÃªm dÃ²ng nÃ y vÆ°á»£t quÃ¡ max_chars vÃ  Ä‘Ã£ cÃ³ ná»™i dung, táº¡o segment má»›i
            if current_length + line_length > max_chars and current_segment:
                # Táº¡o segment: báº¯t Ä‘áº§u báº±ng title (cÃ³ dáº¥u ' á»Ÿ Ä‘áº§u), sau Ä‘Ã³ lÃ  cÃ¡c dÃ²ng content
                # Má»—i dÃ²ng cÃ¡ch nhau bá»Ÿi 2 dÃ²ng trá»‘ng
                all_lines = [f"'{title}"] + current_segment
                segment_content = '\n\n'.join(all_lines)
                
                segments.append({
                    'id': f'Chapter_{chapter_number}_Segment_{segment_counter}',
                    'title': title,
                    'content': segment_content
                })
                
                segment_counter += 1
                current_segment = []
                current_length = 0
            
            current_segment.append(line)
            current_length += line_length
        
        # ThÃªm segment cuá»‘i cÃ¹ng
        if current_segment:
            # Táº¡o segment: báº¯t Ä‘áº§u báº±ng title (cÃ³ dáº¥u ' á»Ÿ Ä‘áº§u), sau Ä‘Ã³ lÃ  cÃ¡c dÃ²ng content
            all_lines = [f"'{title}"] + current_segment
            segment_content = '\n\n'.join(all_lines)
            
            segments.append({
                'id': f'Chapter_{chapter_number}_Segment_{segment_counter}',
                'title': title,
                'content': segment_content
            })
        
        return segments
    
    def detect_chapter_number(self, file_path: str) -> int:
        """
        PhÃ¡t hiá»‡n sá»‘ chapter tá»« tÃªn file
        
        Args:
            file_path: ÄÆ°á»ng dáº«n file
            
        Returns:
            int: Sá»‘ chapter (hoáº·c None náº¿u khÃ´ng phÃ¡t hiá»‡n Ä‘Æ°á»£c)
        """
        file_name = Path(file_path).stem
        
        # Thá»­ tÃ¬m sá»‘ trong tÃªn file (vÃ­ dá»¥: p-014.xhtml -> 14)
        match = re.search(r'(\d+)', file_name)
        if match:
            return int(match.group(1))
        
        return None
    
    def process(self, max_chars: int = 2000) -> Tuple[List[Dict], List[Dict]]:
        """
        Xá»­ lÃ½ toÃ n bá»™ EPUB vÃ  tÃ¡ch ná»™i dung
        
        Args:
            max_chars: Sá»‘ kÃ½ tá»± tá»‘i Ä‘a cho má»—i segment
        
        Returns:
            Tuple[List[Dict], List[Dict]]: (chinese_segments, japanese_segments)
        """
        print(f"\nğŸ“– Äang xá»­ lÃ½ EPUB: {Path(self.epub_path).name}")
        print(f"   Tham sá»‘: max_chars = {max_chars}")
        
        # 1. Giáº£i nÃ©n EPUB
        self.extract_epub()
        
        # 2. TÃ¬m cÃ¡c file XHTML
        xhtml_files = self.find_xhtml_files()
        
        if not xhtml_files:
            print("âŒ KhÃ´ng tÃ¬m tháº¥y file XHTML nÃ o!")
            return ([], [])
        
        # 3. Parse tá»«ng file
        chinese_segments = []
        japanese_segments = []
        
        for idx, xhtml_file in enumerate(xhtml_files, 0):  # Báº¯t Ä‘áº§u tá»« 0
            print(f"   [{idx+1}/{len(xhtml_files)}] {Path(xhtml_file).name}")
            
            # PhÃ¡t hiá»‡n sá»‘ chapter tá»« tÃªn file
            chapter_num = self.detect_chapter_number(xhtml_file)
            
            # Náº¿u khÃ´ng phÃ¡t hiá»‡n Ä‘Æ°á»£c, dÃ¹ng index (báº¯t Ä‘áº§u tá»« 0)
            if chapter_num is None:
                chapter_num = idx
            else:
                # Trá»« 2 Ä‘á»ƒ báº¯t Ä‘áº§u tá»« Chapter_0 (vÃ¬ p-002 -> Chapter_0)
                chapter_num = chapter_num - 2
            
            # Parse file
            ch_segs, jp_segs = self.parse_xhtml_file(xhtml_file, chapter_num, max_chars)
            
            chinese_segments.extend(ch_segs)
            japanese_segments.extend(jp_segs)
        
        self.chinese_segments = chinese_segments
        self.japanese_segments = japanese_segments
        
        print(f"\nâœ“ TÃ¡ch xong:")
        print(f"   - Trung: {len(chinese_segments)} segments")
        print(f"   - Nháº­t: {len(japanese_segments)} segments")
        
        return (chinese_segments, japanese_segments)
    
    def save_yaml(self, segments: List[Dict], output_path: str) -> bool:
        """
        LÆ°u segments ra file YAML
        
        Args:
            segments: List cÃ¡c segment
            output_path: ÄÆ°á»ng dáº«n file output
            
        Returns:
            bool: True náº¿u thÃ nh cÃ´ng
        """
        try:
            # ÄÄƒng kÃ½ custom representer
            yaml.add_representer(str, represent_multiline_string, Dumper=CustomDumper)
            
            with open(output_path, 'w', encoding='utf-8') as f:
                yaml.dump(
                    segments,
                    f,
                    allow_unicode=True,
                    sort_keys=False,
                    default_flow_style=False,
                    Dumper=CustomDumper
                )
            
            print(f"   âœ“ ÄÃ£ lÆ°u: {output_path}")
            return True
            
        except Exception as e:
            print(f"   âœ— Lá»—i khi lÆ°u file: {e}")
            return False
    
    def cleanup(self):
        """Dá»n dáº¹p thÆ° má»¥c temp"""
        if self.temp_dir and Path(self.temp_dir).exists():
            import shutil
            shutil.rmtree(self.temp_dir)
            print(f"âœ“ ÄÃ£ dá»n dáº¹p thÆ° má»¥c temp")
    
    def split_and_save(self, output_dir: str = None, max_chars: int = 2000):
        """
        Xá»­ lÃ½ vÃ  lÆ°u cáº£ 2 file YAML
        
        Args:
            output_dir: ThÆ° má»¥c output (máº·c Ä‘á»‹nh = cÃ¹ng thÆ° má»¥c vá»›i EPUB)
            max_chars: Sá»‘ kÃ½ tá»± tá»‘i Ä‘a cho má»—i segment
        """
        # Process
        chinese_segments, japanese_segments = self.process(max_chars)
        
        if not chinese_segments and not japanese_segments:
            print("âŒ KhÃ´ng cÃ³ ná»™i dung nÃ o Ä‘Æ°á»£c tÃ¡ch!")
            return
        
        # XÃ¡c Ä‘á»‹nh output directory
        if output_dir is None:
            output_dir = Path(self.epub_path).parent
        else:
            output_dir = Path(output_dir)
            output_dir.mkdir(parents=True, exist_ok=True)
        
        # Táº¡o tÃªn file output
        epub_name = Path(self.epub_path).stem
        
        print(f"\nğŸ’¾ Äang lÆ°u file YAML...")
        
        # LÆ°u file Trung
        if chinese_segments:
            chinese_path = output_dir / f"{epub_name}_chinese.yaml"
            self.save_yaml(chinese_segments, str(chinese_path))
        
        # LÆ°u file Nháº­t
        if japanese_segments:
            japanese_path = output_dir / f"{epub_name}_japanese.yaml"
            self.save_yaml(japanese_segments, str(japanese_path))
        
        # Cleanup
        self.cleanup()
        
        print(f"\nâœ… HoÃ n thÃ nh!")


def main():
    """Interactive interface"""
    print("=" * 70)
    print("  EPUB BILINGUAL SPLITTER - TÃ¡ch Song Ngá»¯ Trung-Nháº­t")
    print("=" * 70)
    
    # Nháº­p file EPUB
    while True:
        epub_path = input("\nNháº­p Ä‘Æ°á»ng dáº«n file EPUB: ").strip().strip('"\'')
        
        if not epub_path:
            print("âŒ Vui lÃ²ng nháº­p Ä‘Æ°á»ng dáº«n file!")
            continue
        
        if not os.path.exists(epub_path):
            print(f"âŒ File khÃ´ng tá»“n táº¡i: {epub_path}")
            continue
        
        if not epub_path.lower().endswith('.epub'):
            print("âŒ File pháº£i cÃ³ Ä‘á»‹nh dáº¡ng .epub!")
            continue
        
        break
    
    # Nháº­p output directory (optional)
    print("\nThÆ° má»¥c lÆ°u output:")
    print("   (Enter = cÃ¹ng thÆ° má»¥c vá»›i EPUB)")
    output_dir = input("   Path: ").strip().strip('"\'')
    
    if not output_dir:
        output_dir = None
    
    # Nháº­p max_chars
    print("\nSá»‘ kÃ½ tá»± tá»‘i Ä‘a má»—i segment:")
    max_chars_input = input("   [máº·c Ä‘á»‹nh = 2000]: ").strip()
    max_chars = int(max_chars_input) if max_chars_input else 2000
    
    # Confirm
    print("\n" + "=" * 70)
    print("THÃ”NG TIN:")
    print(f"   Input:      {epub_path}")
    print(f"   Output:     {output_dir or Path(epub_path).parent}")
    print(f"   Max chars:  {max_chars}")
    
    confirm = input("\nBáº¯t Ä‘áº§u tÃ¡ch? (y/n): ").strip().lower()
    if confirm not in ['y', 'yes', 'cÃ³', '']:
        print("ÄÃ£ há»§y!")
        return
    
    # Process
    try:
        splitter = EPUBBilingualSplitter(epub_path)
        splitter.split_and_save(output_dir, max_chars)
        
    except Exception as e:
        print(f"\nâŒ Lá»—i: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ÄÃ£ há»§y chÆ°Æ¡ng trÃ¬nh.")
    except Exception as e:
        print(f"\nâŒ Lá»—i: {e}")
        input("\nNháº¥n Enter Ä‘á»ƒ thoÃ¡t...")


#!/usr/bin/env python3
"""
YAML Context Analyzer - Ti·ªán √≠ch ph√¢n t√≠ch ng·ªØ c·∫£nh t·ª´ file YAML
ƒê·ªçc file YAML, g·ª≠i t·ª´ng segment ƒë·∫øn API ƒë·ªÉ t·∫°o t√≥m t·∫Øt ng·ªØ c·∫£nh,
sau ƒë√≥ ghi k·∫øt qu·∫£ v√†o m·ªôt file YAML m·ªõi.
ƒê√¢y l√† m·ªôt ti·ªán √≠ch ƒë·ªôc l·∫≠p.
"""

import os
import sys
import yaml
import json
import openai
import threading
import queue
from datetime import datetime
import time

# Th√™m ƒë∆∞·ªùng d·∫´n ƒë·ªÉ import CustomDumper
script_dir = os.path.dirname(os.path.abspath(__file__))
enhanced_dir = os.path.abspath(os.path.join(script_dir, '../enhanced'))
sys.path.append(enhanced_dir)

try:
    from clean_segment import CustomDumper
except ImportError:
    print("C·∫£nh b√°o: Kh√¥ng th·ªÉ import CustomDumper. S·∫Ω s·ª≠ d·ª•ng Dumper m·∫∑c ƒë·ªãnh c·ªßa PyYAML.")
    CustomDumper = yaml.Dumper

# --- C√°c h√†m v√† Class ti·ªán √≠ch ---

def load_config(config_path='yaml_context_analyzer_config.json'):
    """T·∫£i file c·∫•u h√¨nh."""
    full_config_path = os.path.join(script_dir, config_path)
    if not os.path.exists(full_config_path):
        print(f"L·ªói: File c·∫•u h√¨nh '{full_config_path}' kh√¥ng t·ªìn t·∫°i.")
        return None
    try:
        with open(full_config_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print(f"L·ªói khi ƒë·ªçc file c·∫•u h√¨nh: {e}")
        return None

def load_yaml(file_path):
    """T·∫£i file YAML m·ªôt c√°ch an to√†n."""
    if not os.path.exists(file_path):
        print(f"L·ªói: File YAML ngu·ªìn '{file_path}' kh√¥ng t·ªìn t·∫°i.")
        return None
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    except Exception as e:
        print(f"L·ªói khi ƒë·ªçc file YAML '{file_path}': {e}")
        return None

def load_prompt(file_path):
    """T·∫£i n·ªôi dung prompt t·ª´ file."""
    if not os.path.exists(file_path):
        print(f"L·ªói: File prompt '{file_path}' kh√¥ng t·ªìn t·∫°i.")
        return None
    with open(file_path, 'r', encoding='utf-8') as f:
        return f.read().strip()

# --- Logic Ph√¢n T√≠ch ---

def analysis_worker(q, result_dict, client, system_prompt, model, temperature, max_tokens, lock, total_segments):
    """Worker cho thread ph√¢n t√≠ch segment v√† tr·∫£ v·ªÅ t√≥m t·∫Øt text."""
    while not q.empty():
        try:
            index, segment = q.get(block=False)
            segment_id = segment.get('id', 'Unknown_ID')
            original_title = segment.get('title', '')
            content = segment.get('content', '')

            with lock:
                processed_count = len(result_dict)
                print(f"[{processed_count + 1}/{total_segments}] ƒêang ph√¢n t√≠ch: {segment_id}...")

            if not content.strip():
                with lock:
                    print(f"C·∫£nh b√°o: B·ªè qua segment {segment_id} v√¨ kh√¥ng c√≥ n·ªôi dung.")
                # V·∫´n t·∫°o segment r·ªóng ƒë·ªÉ gi·ªØ ƒë√∫ng th·ª© t·ª±
                result_dict[index] = {'id': segment_id, 'title': original_title, 'content': ''}
                q.task_done()
                continue

            try:
                response = client.chat.completions.create(
                    model=model,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": content}
                    ],
                    temperature=temperature,
                    max_tokens=max_tokens,
                )
                
                # Ki·ªÉm tra API c√≥ tr·∫£ v·ªÅ n·ªôi dung kh√¥ng
                if response.choices and response.choices[0].message and response.choices[0].message.content is not None:
                    summary_text = response.choices[0].message.content
                    new_segment = {
                        'id': segment_id,
                        'title': original_title,
                        'content': summary_text.strip()
                    }
                    result_dict[index] = new_segment
                else:
                    # X·ª≠ l√Ω tr∆∞·ªùng h·ª£p kh√¥ng c√≥ n·ªôi dung (b·ªã filter, etc.)
                    finish_reason = response.choices[0].finish_reason if response.choices else 'unknown'
                    with lock:
                        print(f"‚ö†Ô∏è C·∫£nh b√°o: API kh√¥ng tr·∫£ v·ªÅ n·ªôi dung cho {segment_id} (l√Ω do: {finish_reason}). Gi·ªØ l·∫°i n·ªôi dung g·ªëc.")
                    result_dict[index] = segment # Gi·ªØ l·∫°i segment g·ªëc

            except Exception as e:
                with lock:
                    print(f"‚ùå L·ªói API cho segment {segment_id}: {e}")
                # N·∫øu l·ªói, gi·ªØ l·∫°i content g·ªëc ƒë·ªÉ kh√¥ng m·∫•t d·ªØ li·ªáu
                result_dict[index] = segment
            
            q.task_done()

        except queue.Empty:
            break

def analyze_and_summarize_threaded(segments, client, system_prompt, config):
    """X·ª≠ l√Ω t√≥m t·∫Øt c√°c segment b·∫±ng threading."""
    q = queue.Queue()
    # D√πng dict ƒë·ªÉ ƒë·∫£m b·∫£o th·ª© t·ª± c·ªßa c√°c segment ƒë∆∞·ª£c gi·ªØ nguy√™n
    result_dict = {}
    lock = threading.Lock()
    total_segments = len(segments)
    
    for i, seg in enumerate(segments):
        q.put((i, seg))

    api_config = config['api_settings']
    num_threads = min(api_config.get("concurrent_requests", 5), total_segments)
    threads = []
    
    print(f"\nB·∫Øt ƒë·∫ßu t√≥m t·∫Øt {total_segments} segment v·ªõi {num_threads} threads...")
    
    for _ in range(num_threads):
        t = threading.Thread(
            target=analysis_worker,
            args=(
                q, result_dict, client, system_prompt,
                api_config["model"], api_config["temperature"], api_config["max_tokens"], lock, total_segments
            )
        )
        t.daemon = True
        t.start()
        threads.append(t)
    
    q.join() # Ch·ªù queue ƒë∆∞·ª£c x·ª≠ l√Ω h·∫øt
    
    # Chuy·ªÉn ƒë·ªïi dict k·∫øt qu·∫£ th√†nh list theo ƒë√∫ng th·ª© t·ª±
    final_results = [result_dict[i] for i in sorted(result_dict.keys())]
    return final_results

def save_output_yaml(data, output_dir, base_filename):
    """L∆∞u danh s√°ch c√°c segment ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω ra file YAML."""
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
        
    output_file_path = os.path.join(output_dir, f"{base_filename}_context.yaml")
    
    try:
        with open(output_file_path, 'w', encoding='utf-8') as f:
            yaml.dump(data, f, allow_unicode=True, sort_keys=False, Dumper=CustomDumper)
        print(f"‚úÖ K·∫øt qu·∫£ ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o file YAML: {output_file_path}")
    except Exception as e:
        print(f"‚ùå L·ªói khi l∆∞u file YAML: {e}")


# --- Main Workflow ---
def main():
    """H√†m ch√≠nh ƒë·ªÉ ch·∫°y script."""
    print("="*60)
    print("      YAML CONTEXT ANALYZER - TI·ªÜN √çCH PH√ÇN T√çCH NG·ªÆ C·∫¢NH")
    print("="*60)

    # 1. T·∫£i config
    config_path = 'yaml_context_analyzer_config.json'
    config = load_config(config_path)
    if not config:
        sys.exit(1)
    
    api_config = config['api_settings']
    paths_config = config['paths']

    # 2. L·∫•y th√¥ng tin t·ª´ config
    yaml_file = paths_config.get("source_yaml_file")
    if not yaml_file or "ƒê∆Ø·ªúNG_D·∫™N" in yaml_file:
        print(f"L·ªói: Vui l√≤ng ch·ªâ ƒë·ªãnh 'source_yaml_file' h·ª£p l·ªá trong file '{config_path}'.")
        sys.exit(1)
        
    segments = load_yaml(yaml_file)
    if not segments:
        sys.exit(1)

    prompt_file = paths_config.get("system_prompt_file")
    if not prompt_file or not os.path.exists(prompt_file):
        print(f"L·ªói: Vui l√≤ng ch·ªâ ƒë·ªãnh 'system_prompt_file' h·ª£p l·ªá trong file '{config_path}'.")
        sys.exit(1)

    system_prompt = load_prompt(prompt_file)
    if not system_prompt:
        sys.exit(1)

    # 3. Ki·ªÉm tra API key
    if "YOUR_OPENAI_API_KEY" in api_config.get("api_key", ""):
        api_key = input("Vui l√≤ng nh·∫≠p OpenAI API Key c·ªßa b·∫°n: ").strip()
        if not api_key:
            print("API key l√† b·∫Øt bu·ªôc. D·ª´ng ch∆∞∆°ng tr√¨nh.")
            sys.exit(1)
        api_config['api_key'] = api_key
    
    print(f"\nB·∫Øt ƒë·∫ßu ph√¢n t√≠ch file: {yaml_file}")
    print(f"S·ª≠ d·ª•ng system prompt: {prompt_file}")
    
    # 4. Chu·∫©n b·ªã v√† th·ª±c thi
    client = openai.OpenAI(api_key=api_config["api_key"], base_url=api_config["base_url"])
    
    summarized_segments = analyze_and_summarize_threaded(segments, client, system_prompt, config)

    if not summarized_segments:
        print("\nKh√¥ng c√≥ k·∫øt qu·∫£ n√†o ƒë∆∞·ª£c x·ª≠ l√Ω. D·ª´ng ch∆∞∆°ng tr√¨nh.")
        sys.exit(1)
        
    # 5. L∆∞u k·∫øt qu·∫£
    base_filename = os.path.splitext(os.path.basename(yaml_file))[0]
    output_dir = paths_config.get("output_dir", "output")
    
    save_output_yaml(summarized_segments, output_dir, base_filename)
    
    print("\nüéâ Ph√¢n t√≠ch ho√†n t·∫•t!")

if __name__ == "__main__":
    main() 
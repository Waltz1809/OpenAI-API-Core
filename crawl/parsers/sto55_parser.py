#!/usr/bin/env python3
"""
Sto55 Parser Module
===================

Parser chuyÃªn dá»¥ng cho sto55.com (æ€å…”é–±è®€)
TrÃ­ch xuáº¥t: title, content, next_url

Sá»­ dá»¥ng JSON-only approach
"""

import re
from urllib.parse import urljoin
from .base_parser import BaseParser, StandardParserMixin


class Sto55Parser(StandardParserMixin):
    """Parser cho sto55.com"""
    
    @staticmethod
    def extract_content(page, current_url):
        """
        Extract content tá»« má»™t trang sto55.com

        Args:
            page: Playwright page object
            current_url: URL hiá»‡n táº¡i

        Returns:
            dict: {
                'title': str,
                'volume': str,
                'content': str,
                'next_url': str,
                'success': bool
            }
        """
        try:
            # Extract title tá»« h1.pt10
            title = "KhÃ´ng cÃ³ tiÃªu Ä‘á»"
            title_el = page.query_selector('h1.pt10')
            if title_el:
                title = title_el.inner_text().strip()
                print(f"  âœ… TÃ¬m tháº¥y title: {title}")
            else:
                print(f"  âš ï¸  KhÃ´ng tÃ¬m tháº¥y title!")

            # Volume khÃ´ng cÃ³ trÃªn site nÃ y
            volume = ""

            # Extract content tá»« div.readcotent
            content = ""
            content_div = page.query_selector('div.readcotent')
            if content_div:
                print(f"  âœ… TÃ¬m tháº¥y div.readcotent")
                # Láº¥y HTML content
                content_html = content_div.inner_html()
                
                # Clean HTML vÃ  extract text
                content_text = Sto55Parser._clean_html_content(content_html)
                content = content_text.strip()
                print(f"  ğŸ“ Cleaned content length: {len(content)} chars")
            else:
                print(f"  âŒ KHÃ”NG tÃ¬m tháº¥y div.readcotent!")
                content = ""

            # Extract next URL tá»« navigation links
            next_url = ""
            try:
                # TÃ¬m link cÃ³ id="linkNext"
                next_link = page.query_selector('#linkNext')
                if next_link:
                    href = next_link.get_attribute('href')
                    if href:
                        next_url = urljoin(current_url, href)
                        # Kiá»ƒm tra náº¿u next_url trá» vá» catalog thÃ¬ khÃ´ng cÃ³ next
                        if '/book/' in next_url and next_url.count('/') == 4:
                            # URL format: https://sto55.com/book/57037/ (catalog)
                            # vs https://sto55.com/book/57037/28554626.html (chapter)
                            if not next_url.endswith('.html'):
                                next_url = ""
                        print(f"  â¡ï¸  Next URL: {next_url}")
                    else:
                        print(f"  ğŸ KhÃ´ng cÃ³ next URL")
            except Exception as e:
                print(f"  âš ï¸  Lá»—i extract next_url: {e}")

            print(f"  ğŸ“Š Káº¿t quáº£ extract:")
            print(f"    - Title: {title}")
            print(f"    - Content length: {len(content)}")
            print(f"    - Next URL: {next_url}")
            print(f"    - Success: {bool(content)}")

            return {
                'title': title,
                'volume': volume,
                'content': content,
                'next_url': next_url,
                'success': bool(content)
            }

        except Exception as e:
            print(f"âš ï¸  Lá»—i extract content tá»« sto55: {e}")
            import traceback
            traceback.print_exc()
            return {
                'title': "",
                'volume': "",
                'content': "",
                'next_url': "",
                'success': False
            }
    
    @staticmethod
    def _clean_html_content(html_content):
        """
        Clean HTML content tá»« sto55.com
        
        Loáº¡i bá»:
        - Ads (ADVERTISEMENT divs, adsbygoogle ins)
        - Scripts
        - Navigation text
        - Watermarks
        
        Args:
            html_content (str): Raw HTML content
            
        Returns:
            str: Cleaned text content
        """
        if not html_content:
            return ""
        
        # Loáº¡i bá» script tags
        html_content = re.sub(r'<script[^>]*>.*?</script>', '', html_content, flags=re.DOTALL | re.IGNORECASE)
        
        # Loáº¡i bá» ads divs
        html_content = re.sub(r'<div[^>]*class="ADVERTISEMENT"[^>]*>.*?</div>', '', html_content, flags=re.DOTALL | re.IGNORECASE)
        
        # Loáº¡i bá» adsbygoogle ins tags
        html_content = re.sub(r'<ins[^>]*class="adsbygoogle"[^>]*>.*?</ins>', '', html_content, flags=re.DOTALL | re.IGNORECASE)
        
        # Loáº¡i bá» div with style="text-align:center;" (chá»©a ads)
        html_content = re.sub(r'<div[^>]*style="text-align:center;"[^>]*>.*?</div>', '', html_content, flags=re.DOTALL | re.IGNORECASE)
        
        # Loáº¡i bá» iframe tags
        html_content = re.sub(r'<iframe[^>]*>.*?</iframe>', '', html_content, flags=re.DOTALL | re.IGNORECASE)
        
        # Replace <br> vá»›i newlines
        html_content = html_content.replace('<br><br>', '\n\n')
        html_content = html_content.replace('<br>', '\n')
        html_content = html_content.replace('<br/>', '\n')
        html_content = html_content.replace('<br />', '\n')
        
        # Loáº¡i bá» táº¥t cáº£ HTML tags cÃ²n láº¡i
        html_content = re.sub(r'<[^>]+>', '', html_content)
        
        # Decode HTML entities
        html_content = html_content.replace('&nbsp;', ' ')
        html_content = html_content.replace('&lt;', '<')
        html_content = html_content.replace('&gt;', '>')
        html_content = html_content.replace('&amp;', '&')
        html_content = html_content.replace('&#8195;&#8195;', '  ')
        
        # Split thÃ nh lines vÃ  clean
        lines = html_content.split('\n')
        clean_lines = []
        
        for line in lines:
            line = line.strip()
            
            # Skip empty lines
            if not line:
                continue
            
            # Skip watermark lines
            if any(watermark in line for watermark in [
                'æœ¬ç« ç¯€ä¾†æºæ–¼',
                'STO55.COM',
                'sto55.com',
                'ğ•Šğ•‹ğ•†ğŸğŸ',
                'â„‚ğ•†ğ•„'
            ]):
                continue
            
            # Skip ads text
            if 'ADVERTISEMENT' in line:
                continue
            
            # ThÃªm line há»£p lá»‡
            clean_lines.append(line)
        
        # ThÃªm dáº¥u ' vÃ o dÃ²ng Ä‘áº§u tiÃªn (náº¿u cÃ³)
        if clean_lines:
            clean_lines[0] = "'" + clean_lines[0]
        
        # Join vá»›i double newlines Ä‘á»ƒ táº¡o paragraphs
        return '\n\n'.join(clean_lines)
    
    @staticmethod
    def clean_content(content):
        """
        Clean content cho sto55.com
        
        Args:
            content (str): Raw content
            
        Returns:
            str: Cleaned content
        """
        if not content:
            return ""
        
        # Remove zero-width characters
        replacements = {
            '\u200b': '',  # Zero-width space
            '\u200c': '',  # Zero-width non-joiner
            '\u200d': '',  # Zero-width joiner
            '\ufeff': '',  # Byte order mark
        }
        
        for old, new in replacements.items():
            content = content.replace(old, new)
        
        # Remove extra whitespace (but preserve paragraph breaks)
        content = re.sub(r'[ \t]+', ' ', content)  # Collapse spaces and tabs
        content = re.sub(r'\n\s*\n\s*\n+', '\n\n', content)  # Collapse multiple newlines
        
        # Remove any remaining watermarks
        content = re.sub(r'æœ¬ç« ç¯€ä¾†æºæ–¼.*?COM', '', content, flags=re.IGNORECASE)
        content = re.sub(r'STO55\.COM', '', content, flags=re.IGNORECASE)
        
        return content.strip()

